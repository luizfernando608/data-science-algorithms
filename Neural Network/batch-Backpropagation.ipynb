{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\r\n",
    "from scipy.stats import mode\r\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, plot_confusion_matrix, roc_curve, precision_recall_curve\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_part1 = pd.read_csv(\"Part 1.tsv\", sep=\"\\t\")\r\n",
    "X = df_part1.drop(\"label\", axis=1).values\r\n",
    "y = df_part1[\"label\"].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Neural_Network(BaseEstimator, ClassifierMixin):\r\n",
    "    def __init__(self):\r\n",
    "        self.name = \"Neural Network\"\r\n",
    "        self.learning_rate = 0.01\r\n",
    "        self.costs = []\r\n",
    "        self.accuracies = []\r\n",
    "        self.classes_ = [0,1]\r\n",
    "\r\n",
    "    def _sigmoid(self, Z:np.ndarray):\r\n",
    "        return 1.0 / (1.0 + np.exp(-Z))\r\n",
    "\r\n",
    "    def _sigmoid_derivative(self, output:np.ndarray):\r\n",
    "        return output * (1.0 - output)\r\n",
    "\r\n",
    "    def _cost_function(self, y:np.ndarray, y_hat:np.ndarray):\r\n",
    "        return -np.sum(y*(np.log(y_hat)) + (1 - y)*np.log(1 - y_hat)) / y.shape[0]\r\n",
    "\r\n",
    "    def _cost_gradient(self, y:np.ndarray, y_hat:np.ndarray):\r\n",
    "        return -np.divide(y, y_hat) + np.divide(1.0 - y, 1.0 - y_hat)\r\n",
    "    \r\n",
    "    def _tanh(self, Z:np.ndarray) -> np.ndarray:\r\n",
    "        return np.tanh(Z)\r\n",
    "\r\n",
    "    def _sech(self, Z:np.ndarray) -> np.ndarray:\r\n",
    "        return 1/np.cosh(Z)\r\n",
    "\r\n",
    "    def _tanh_derivative(self,Z:np.ndarray) -> np.ndarray:\r\n",
    "        return self._sech(Z)**2\r\n",
    "\r\n",
    "    def forward_pass(self, X_train_1:np.ndarray, X_train_2:np.ndarray):\r\n",
    "        \r\n",
    "        self.A0 = np.hstack([X_train_1,np.ones( (X_train_1.shape[0],1) )] ).T\r\n",
    "\r\n",
    "        self.Z1 = np.dot(self.W1, self.A0)\r\n",
    "\r\n",
    "        self.A1 = self._tanh(self.Z1)\r\n",
    "        self.A1 = np.concatenate((self.A1, X_train_2.T), axis=0)\r\n",
    "\r\n",
    "        self.A1 = np.vstack([self.A1, np.ones((1, self.A1.shape[1] ))])\r\n",
    "        self.Z2 = np.dot(self.W2, self.A1)\r\n",
    "\r\n",
    "        self.A2 = self._sigmoid(self.Z2)\r\n",
    "\r\n",
    "        # self.accuracies.append(np.round(self.A))\r\n",
    "        self.accuracies.append(np.mean(np.round(self.A2)==y_train))\r\n",
    "\r\n",
    "        \r\n",
    "    def backward_pass(self, y_train:np.ndarray):\r\n",
    "        self.dA2 = self._cost_gradient(y_train, self.A2)\r\n",
    "        self.dZ2 = self.dA2*self._sigmoid_derivative(self._sigmoid(self.Z2))\r\n",
    "\r\n",
    "        self.m1 = self.A1.shape[1]\r\n",
    "        self.dW2 = np.dot(self.dZ2, self.A1.T)/self.m1\r\n",
    "        \r\n",
    "        self.dA1 = np.dot(self.W2[:,:1].T, self.dZ2)\r\n",
    "\r\n",
    "        self.dZ1 = self.dA1*self._tanh_derivative(self._tanh(self.Z1))\r\n",
    "\r\n",
    "        self.m0 = self.A0.shape[1]\r\n",
    "        self.dW1 = self.dZ1 @ self.A0.T/self.m0\r\n",
    "\r\n",
    "        self.W1 -= self.dW1*self.learning_rate\r\n",
    "        self.W2 -= self.dW2*self.learning_rate\r\n",
    "\r\n",
    "        self.costs.append(self._cost_function(y_train, self.A2))\r\n",
    "\r\n",
    "\r\n",
    "        \r\n",
    "    def fit(self, X_train:np.ndarray, y_train:np.ndarray, epochs=1000):\r\n",
    "        # Dessa maneira, o modelo funciona com qualquer dataset\r\n",
    "        # E, também, funciona com o atual dataset obedecendo a forma pedida pelo trabalho\r\n",
    "        self.input_hidden_1 = X_train.shape[1]//2\r\n",
    "        self.input_hidden_2 = X_train.shape[1]//2 + X_train.shape[1]%2 + 1\r\n",
    "        \r\n",
    "        self.W1 = np.random.random((1, self.input_hidden_1+1))\r\n",
    "        self.W2 = np.random.random((1, self.input_hidden_2+1))\r\n",
    "        \r\n",
    "        self.epochs = epochs\r\n",
    "\r\n",
    "        X_train_1 = X_train[:, 0:self.input_hidden_1]\r\n",
    "        X_train_2 = X_train[:, self.input_hidden_1:]\r\n",
    "        \r\n",
    "        for e in range(self.epochs):\r\n",
    "            self.forward_pass(X_train_1, X_train_2)\r\n",
    "            self.backward_pass(y_train)\r\n",
    "        return self\r\n",
    "    \r\n",
    "    def predict_proba(self, X_test:np.ndarray):\r\n",
    "        X_test_1 = X_test[:, 0:self.input_hidden_1]\r\n",
    "        X_test_2 = X_test[:, self.input_hidden_1:]\r\n",
    "        A0 = np.hstack([X_test_1, np.ones( (X_test_1.shape[0],1) )] ).T\r\n",
    "        \r\n",
    "        Z1 = np.dot(self.W1, A0)\r\n",
    "        A1 = self._tanh(Z1)\r\n",
    "        A1 = np.concatenate((A1, X_test_2.T), axis=0)\r\n",
    "\r\n",
    "        A1 = np.vstack([A1, np.ones((1, A1.shape[1] ))])\r\n",
    "        \r\n",
    "        Z2 = np.dot(self.W2, A1)\r\n",
    "\r\n",
    "        A2 = self._sigmoid(Z2)\r\n",
    "        \r\n",
    "        return A2[0]\r\n",
    "    \r\n",
    "    def predict(self, X_test:np.ndarray):\r\n",
    "        return np.round(self.predict_proba(X_test))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NN = Neural_Network()\r\n",
    "NN.fit(X_train, y_train, 5000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "report = pd.DataFrame(classification_report(y_test, NN.predict(X_test), output_dict=True))\r\n",
    "metrics = {}\r\n",
    "metrics[\"Accuracy\"] = [report[\"accuracy\"].mean(axis=0)]\r\n",
    "metrics[\"Precision\"] = [report.mean(axis=1)[\"precision\"]]\r\n",
    "metrics[\"Recall\"] = [report.mean(axis=1)[\"recall\"]]\r\n",
    "metrics[\"AUC-ROC\"] = [roc_auc_score(y_test, NN.predict_proba(X_test))]\r\n",
    "metrics[\"AUC-PR\"] = [average_precision_score(y_test, NN.predict_proba(X_test))]\r\n",
    "\r\n",
    "table_metrics = pd.DataFrame(metrics)\r\n",
    "table_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(NN,X_test, y_test)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Colocar título e legenda\r\n",
    "fig, ax = plt.subplots()\r\n",
    "\r\n",
    "sns.lineplot(x=range(len(NN.costs)), y=NN.costs, label=\"Cost Error\", ax=ax)\r\n",
    "sns.lineplot(x=range(len(NN.accuracies)), y=NN.accuracies, label=\"Trainning Accuracy\", ax=ax)\r\n",
    "ax.set_title(\"Neural Network Error\")\r\n",
    "ax.set_xlabel(\"Epochs\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}