{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Trees\r\n",
    "## Exercise 1 -- Download and load the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np \r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\r\n",
    "\r\n",
    "X = data.loc[:, data.columns != 'class'].values\r\n",
    "y = data['class'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 3.6216 ,  8.6661 , -2.8073 , -0.44699])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "income_data = pd.read_csv(\"adult.data\", \r\n",
    "        names=[\"age\", \"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\r\n",
    "                \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"], index_col=False)\r\n",
    "\r\n",
    "binary_income_data = pd.get_dummies(income_data).drop(\"income_ <=50K\", axis=1)\r\n",
    "\r\n",
    "X = binary_income_data.drop(\"income_ >50K\", axis=1).values\r\n",
    "y = binary_income_data[\"income_ >50K\"].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2 -- Gini Index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def gini_index(region):\r\n",
    "    \"\"\"\r\n",
    "    Implements the gini index over the classes in a region\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    region : array (1D)\r\n",
    "        array of labels assigned to points in this region\r\n",
    "        \r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    float\r\n",
    "        the Gini Index\r\n",
    "    \"\"\"\r\n",
    "    classes = np.unique(region)\r\n",
    "    N = region.shape[0]\r\n",
    "    gini = 0\r\n",
    "    for c in classes:\r\n",
    "        p = (region == c).sum() / N\r\n",
    "        gini += p*(1-p)\r\n",
    "    return gini"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# test your code\r\n",
    "np.random.seed(0)\r\n",
    "gini_index(np.random.randint(0, 2, 20)), gini_index(np.ones(10)), gini_index(np.zeros(10)), gini_index(np.array([]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.495, 0.0, 0.0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 3 -- Make a split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def split_region(region, feature_index, tau):\r\n",
    "    \"\"\"\r\n",
    "    Given a region, splits it based on the feature indicated by\r\n",
    "    `feature_index`, the region will be split in two, where\r\n",
    "    one side will contain all points with the feature with values \r\n",
    "    lower than `tau`, and the other split will contain the \r\n",
    "    remaining datapoints.\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    region : array of size (n_samples, n_features)\r\n",
    "        a partition of the dataset (or the full dataset) to be split\r\n",
    "    feature_index : int\r\n",
    "        the index of the feature used to make this partition\r\n",
    "    tau : float\r\n",
    "        The threshold used to make this partition\r\n",
    "        \r\n",
    "    Return\r\n",
    "    ------\r\n",
    "    low_partition : array\r\n",
    "        indices of the datapoints in `region` where feature < `tau`\r\n",
    "    high_partition : array\r\n",
    "        indices of the datapoints in `region` where feature < `tau` \r\n",
    "    \"\"\"\r\n",
    "    return np.where(region[:, feature_index] < tau)[0], np.where(region[:, feature_index] >= tau)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "r, l = split_region(X_train, 1, 0)\r\n",
    "print(r.shape, l.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0,) (22792,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4 -- Find the best split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def get_split(X, y):\r\n",
    "    best_gini = 100 # unreasonably high Gini Index\r\n",
    "    best_feature_index = None\r\n",
    "    best_tau = None\r\n",
    "    best_lo = None\r\n",
    "    best_hi = None\r\n",
    "    for feature_index in range(X.shape[1]):\r\n",
    "        for tau in X[:, feature_index]:\r\n",
    "            lo, hi = split_region(X, feature_index, tau)\r\n",
    "            gini = gini_index(y[lo]) + gini_index(y[hi])\r\n",
    "            if gini < best_gini:\r\n",
    "                best_gini = gini\r\n",
    "                best_feature_index = feature_index\r\n",
    "                best_tau = tau\r\n",
    "                best_lo = lo\r\n",
    "                best_hi = hi\r\n",
    "    return {\r\n",
    "        'feature_index': best_feature_index,\r\n",
    "        'tau': best_tau,\r\n",
    "        'low_region' : best_lo,\r\n",
    "        'high_region' : best_hi,\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "get_split(X_train[:2, :], y_train[:2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'feature_index': 0,\n",
       " 'tau': 47,\n",
       " 'low_region': array([0], dtype=int64),\n",
       " 'high_region': array([1], dtype=int64)}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 5 -- Recursive Splitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def recursive_growth(node, min_samples, max_depth, current_depth, X, y):\r\n",
    "    \"\"\"\r\n",
    "    Recursively grows a decision tree.\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    node : dictionary\r\n",
    "        If the node is terminal, it contains only the \"class\" key, which determines the value to be used as a prediction.\r\n",
    "        If the node is not terminal, the dictionary has the structure defined by `get_split`\r\n",
    "    min_samples : int\r\n",
    "        parameter for stopping criterion\r\n",
    "    max_depth : int\r\n",
    "        parameter for stopping criterion\r\n",
    "    depth : int\r\n",
    "        current distance from the root\r\n",
    "    X : array (n_samples, n_features)\r\n",
    "        features (full dataset)\r\n",
    "    y : array (n_samples, )\r\n",
    "        labels (full dataset)\r\n",
    "    \r\n",
    "    Notes\r\n",
    "    -----\r\n",
    "    To create a terminal node, a dictionary is created with a single \"class\" key, and a value that is\r\n",
    "    the class to which the majority of the datapoins in the node belong.\r\n",
    "    \r\n",
    "    'left' and 'right' keys are added to non-terminal nodes, which contain (possibly terminal) nodes \r\n",
    "    from higher levels of the tree:\r\n",
    "    'left' corresponds to the 'low_region' key, and 'right' to the 'high_region' key\r\n",
    "    \"\"\"\r\n",
    "    if 'low_region' in node.keys(): # not a terminal node\r\n",
    "        lo = node['low_region']\r\n",
    "        hi = node['high_region']\r\n",
    "        # process left\r\n",
    "        classes, counts = np.unique(y[lo], return_counts=True)\r\n",
    "        if len(lo) < min_samples or current_depth == max_depth or len(classes) == 1:\r\n",
    "            classes, counts = np.unique(y[lo], return_counts=True)\r\n",
    "            node['left'] = {'class':classes[np.argmax(counts)]}\r\n",
    "        else:\r\n",
    "            node['left'] = get_split(X[lo], y[lo])\r\n",
    "            recursive_growth(node['left'], min_samples, max_depth, current_depth + 1, X, y)\r\n",
    "\r\n",
    "        # process right\r\n",
    "        classes, counts = np.unique(y[hi], return_counts=True)\r\n",
    "        if len(hi) < min_samples or current_depth == max_depth or len(classes) == 1:\r\n",
    "            classes, counts = np.unique(y[hi], return_counts=True)\r\n",
    "            node['right'] = {'class':classes[np.argmax(counts)]}\r\n",
    "        else:\r\n",
    "            node['right'] = get_split(X[hi], y[hi])\r\n",
    "            recursive_growth(node['right'], min_samples, max_depth, current_depth + 1, X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "k = 20\r\n",
    "test_root = get_split(X_train[:k, :], y_train[:k])\r\n",
    "recursive_growth(test_root, 5, 10, 1, X_train[:k, :], y_train[:k])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def print_tree(node, depth):\r\n",
    "    if 'class' in node.keys():\r\n",
    "        print('.  '*(depth-1), f\"[{node['class']}]\")\r\n",
    "    else:\r\n",
    "        print('.  '*depth, f'X_{node[\"feature_index\"]} < {node[\"tau\"]}')\r\n",
    "        print_tree(node['left'], depth+1)\r\n",
    "        print_tree(node['right'], depth+1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print_tree(test_root, 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " X_3 < 7298\n",
      ".   X_37 < 1\n",
      ".  .   X_5 < 50\n",
      ".  .  .   X_33 < 1\n",
      ".  .  .  .   X_33 < 1\n",
      ".  .  .  .  .   X_33 < 1\n",
      ".  .  .  .  .  .   X_33 < 1\n",
      ".  .  .  .  .  .   [0]\n",
      ".  .  .  .  .  .   [1]\n",
      ".  .  .  .  .   [0]\n",
      ".  .  .  .   [1]\n",
      ".  .  .   [0]\n",
      ".  .   [1]\n",
      ".   [0]\n",
      " [1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 6 -- Make a Prediction\n",
    "Use the test_node to predict the class of a compatible dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def predict_sample(node, sample):\r\n",
    "    \"\"\"\r\n",
    "    Makes a prediction based on the decision tree defined by `node`\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    node : dictionary\r\n",
    "        A node created one of the methods above\r\n",
    "    sample : array of size (n_features,)\r\n",
    "        a sample datapoint\r\n",
    "    \"\"\"\r\n",
    "    if 'class' in node.keys():\r\n",
    "        return node['class']\r\n",
    "    if sample[node['feature_index']] < node['tau']:\r\n",
    "        return predict_sample(node['left'], sample)\r\n",
    "    return predict_sample(node['right'], sample)\r\n",
    "        \r\n",
    "def predict(node, X):\r\n",
    "    \"\"\"\r\n",
    "    Makes a prediction based on the decision tree defined by `node`\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    node : dictionary\r\n",
    "        A node created one of the methods above\r\n",
    "    X : array of size (n_samples, n_features)\r\n",
    "        n_samples predictions will be made\r\n",
    "    \"\"\"\r\n",
    "    prediction = np.zeros(X.shape[0])\r\n",
    "    for i, sample in enumerate(X):\r\n",
    "        prediction[i] = predict_sample(node, sample)\r\n",
    "    return prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "root = get_split(X_train, y_train)\r\n",
    "recursive_growth(root, 20, 10, 1, X_train, y_train)\r\n",
    "test_acc = accuracy_score(y_test, predict(root, X_test))\r\n",
    "train_acc = accuracy_score(y_train, predict(root, X_train))\r\n",
    "\r\n",
    "print(f'Train accuracy : {train_acc}')\r\n",
    "print(f'Test accuracy : {test_acc}')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUIZLU~1\\AppData\\Local\\Temp/ipykernel_3652/3618342504.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrecursive_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LUIZLU~1\\AppData\\Local\\Temp/ipykernel_3652/274973268.py\u001b[0m in \u001b[0;36mget_split\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mgini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgini_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgini_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgini\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_gini\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\LUIZLU~1\\AppData\\Local\\Temp/ipykernel_3652/2855862419.py\u001b[0m in \u001b[0;36msplit_region\u001b[1;34m(region, feature_index, tau)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdatapoints\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "13d8c936807e7e3d1a057b88a7c0a7e5ccf7c0ed5e2b15d29dccef87a282ad17"
   }
  },
  "interpreter": {
   "hash": "9d22e210787f932f44a26469d735647043a268fad5da08dd695a23660e1e54d0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}